# Summary


| Date   | Notes
| :----- | :-------------------------------
| July 3 | Worked on implemeneting REINFORCE in MineRL
| July 4 | Debugged MineRL issues
| July 5 | Worked on implemeneting REINFORCE in MineRL
| July 6 | Debugged MineRL issues
| July 7 | Fine Tuned REINFORCE


# Activities


Working on implementing REINFORCE in MineRL: Currently, I am actively working on implementing the REINFORCE algorithm in the MineRL environment. This involves setting up the necessary dependencies and defining a CNN model using PyTorch. I am currently in the process of fine-tuning the implementation and training the model using the REINFORCE algorithm.

Learning about REINFORCE: Alongside the implementation, I have been reading articles to enhance my understanding of REINFORCE. This includes topics such as the normal distribution, learning rate, and loss functions. This has been able to help me effectively implement REINFORCE in MineRL.


# Issues


Challenges in implementing REINFORCE: I faced difficulties in creating the CNN model, mapping actions in the MineRL environment, and accurately calculating the loss function. Overcoming these challenges required careful design and debugging.

Optimization Challenges in REINFORCE Training: One significant issue encountered during the implementation of REINFORCE was the difficulty of training the agent effectively. Training an agent using REINFORCE can be a challenging task due to the scarcity in rewards. I had challanges fine-tuning the hyperparameters to optimize the agent's learning process. I additionally faced application memory issues due to the complexity of my CNN and had to further optimize the CNN to balance memory and CNN complexity.


# Plans


Reading more articles, working on A2C in MineRL, and learning more!
