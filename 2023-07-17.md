# Summary


| Date   | Notes
| :----- | :-------------------------------
| July 10 | Worked on implemeneting REINFORCE in MineRL
| July 11 | Worked on refining REINFORCE in MineRL
| July 12 | Debugged MineRL installation issues
| July 13 | Debugged MineRL installation issues
| July 14 | Researched A2C and started A2C Implementation


# Activities


Installing MineRL on Windows laptop: I worked on setting up the MineRL package on my Windows laptop. However, I am still uncessesfull in installing MineRL.

Implementing Advantage Actor-Critic (A2C): I started working on implementing the A2C algorithm. Specifically, I began creating the actor and critic networks. I designed the networks to process the input data and generate action probabilities and value estimates. Additionally, I started defining the loss function for both the actor and critic.


# Issues


Installation Challenges with MineRL on Windows: I have encountered difficulties installing the MineRL package on my Windows 11 machine. Despite following the installation instructions and attempting various troubleshooting steps, including reinstalling Java, WSL, and clearing temporary folders, I have been unable to successfully install MineRL. I have documented the issue by opening a GitHub issue and provided detailed information about my environment, steps taken, and error logs for further investigation and assistance. (See https://github.com/minerllabs/minerl/issues/722)

Implementing A2C and Challenges with Loss Function and Advantage Calculation: While working on implementing the Advantage Actor-Critic (A2C) algorithm, I faced challenges in calculating loss function and determining the advantage. Additionally, I worked on balancing the complexity of my networks and my computers memory.


# Plans


Reading more articles, working on A2C in MineRL, and learning more!


# Article Summaries

NeurIPS 2020 Competition: The MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors (https://arxiv.org/pdf/2101.11071.pdf)

The MineRL Competition at NeurIPS 2020 advances the field of reinforcement learning by focusing on sample efficiency and leveraging human demonstrations. By utilizing the MineRL-v0 dataset, participants can explore techniques that make the most of limited data sources, enabling the development of more effective and efficient learning algorithms. The insights gained from this competition have broader implications for real-world applications of reinforcement learning, where data scarcity is a common challenge. The techniques and approaches developed in this competition can be applied to a wide range of domains, contributing to the progress of reinforcement learning as a whole.